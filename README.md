# Credit Risk Prediction

A machine learning-based credit risk assessment system that predicts loan default probability for banking applications. Developed during an internship at NBK Egypt using real banking data from Oracle databases.

## ğŸ¯ Project Overview

This project implements a comprehensive credit risk prediction pipeline that:
- Extracts and preprocesses banking data from Oracle databases (1000+ tables)
- Engineers financial features and ratios for loan assessment
- Trains machine learning models to predict loan repayment likelihood
- Provides an interactive Streamlit web interface for real-time predictions

## ğŸ—ï¸ Architecture

### Data Pipeline
1. **Data Extraction**: Oracle Developer App â†’ 1000+ tables (Tememnos R22 AA)
2. **Feature Engineering**: Calculate 17+ derived financial ratios
3. **Preprocessing**: Encoding, scaling, PCA dimensionality reduction
4. **Model Training**: Random Forest with SMOTE balancing
5. **Deployment**: Streamlit UI with real-time prediction

### Technology Stack
- **Backend**: Python, scikit-learn, pandas, numpy
- **UI**: Streamlit
- **Database**: Oracle (Tememnos R22 AA banking system)
- **ML Pipeline**: RandomForest, PCA, SMOTE, StandardScaler
- **DevOps**: Docker, OLLAMA, OpenWebUI (experimental)

## ğŸ“Š Features

### Core Financial Metrics
- **Debt-to-Income Ratio (DTI)**
- **Monthly Payment Burden**
- **Interest Coverage Ratio**
- **Principal-to-Interest Ratio**
- **Effective Interest Rate**
- **Loan-to-Income Exposure**

### Input Categories
- ğŸŒ **Geographical**: Residence, nationality, birthplace
- ğŸ‘¤ **Demographics**: Age, gender, marital status, income
- ğŸ¦ **Account Info**: Customer type, account history, contact dates
- âš ï¸ **KYC/Risk**: Compliance status, risk categorization
- ğŸ’° **Loan Details**: Amount, duration, interest rate, type
- ğŸ’³ **Charges**: Fee structures, posting restrictions

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install streamlit pandas numpy scikit-learn imbalanced-learn
```

### Training the Model
```bash
python train_and_save_artifacts.py
```
This creates the required artifacts:
- `model.pkl` - Trained RandomForest classifier
- `scaler.pkl` - StandardScaler for feature normalization
- `pca.pkl` - PCA transformer for dimensionality reduction
- `features.pkl` - Feature list in training order
- `defaults.pkl` - Median values for missing data imputation
- `encoders.pkl` - Label encoders for categorical variables
- `metadata.pkl` - Date columns and categorical column metadata

### Running the Application
```bash
streamlit run app.py
```

## ğŸ›ï¸ Usage Modes

### 1. Human-Friendly Input
Interactive form with organized sections:
- Dropdown menus for categorical data
- Date pickers for temporal fields
- Numeric inputs with validation
- Real-time calculation of derived financial metrics

### 2. CSV Row Input
Paste raw CSV data for bulk processing:
- Automatic preprocessing pipeline
- Handles missing values and data type conversion
- Maintains compatibility with training data format

## ğŸ§® Feature Engineering

The system automatically calculates 17 derived financial features:

```python
# Example derived features
DTI = TOTAL_LOAN_AMOUNT / TOTAL_MONTHLY_INCOME
MONTHLY_PAYMENT_BURDEN = MONTHLY_PAYMENT / TOTAL_MONTHLY_INCOME
INTEREST_COVERAGE = TOTAL_LOAN_AMOUNT / TOT_INTEREST_AMT
PRINCIPAL_TO_INTEREST_RATIO = LOAN_AMOUNT / TOT_INTEREST_AMT
```

## ğŸ“ˆ Model Performance

The RandomForest classifier with SMOTE balancing provides:
- **Target Classes**: 
  - PDO (Past Due/Overdue) = 0 (High Risk)
  - CUR (Current) = 1 (Low Risk)
- **Evaluation Metrics**: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- **Class Balancing**: SMOTE oversampling for imbalanced datasets

## ğŸ—‚ï¸ File Structure

```
CreditRiskPrediction/
â”œâ”€â”€ train_and_save_artifacts.py  # Model training pipeline
â”œâ”€â”€ app.py                       # Streamlit web application
â”œâ”€â”€ feature eng.csv              # Preprocessed training data
â”œâ”€â”€ model.pkl                    # Trained model artifacts
â”œâ”€â”€ scaler.pkl                   # Feature scaling transformer
â”œâ”€â”€ pca.pkl                      # PCA dimensionality reducer
â”œâ”€â”€ features.pkl                 # Feature list metadata
â”œâ”€â”€ defaults.pkl                 # Default values for imputation
â”œâ”€â”€ encoders.pkl                 # Categorical encoders
â”œâ”€â”€ metadata.pkl                 # Pipeline metadata
â””â”€â”€ README.md                    # Project documentation
```

## ğŸ”„ Pipeline Workflow

1. **Data Loading**: Read CSV with automatic date parsing
2. **Feature Engineering**: Calculate financial ratios and derived metrics
3. **Encoding**: Transform categorical variables using LabelEncoder
4. **Date Processing**: Extract year, month, day, and days-since features
5. **Scaling**: Standardize numeric features using StandardScaler
6. **Dimensionality Reduction**: Apply PCA (95% variance retention)
7. **Balancing**: Use SMOTE for minority class oversampling
8. **Training**: Fit RandomForest with balanced class weights
9. **Evaluation**: Comprehensive metrics and confusion matrix analysis

## ğŸ’¡ Key Innovations

- **Comprehensive Feature Engineering**: 17+ derived financial ratios
- **Robust Date Handling**: Automatic parsing and feature extraction
- **Dual Input Modes**: Human-friendly UI + CSV batch processing
- **Real-time Calculations**: Live financial metric computation
- **Production Ready**: Artifact-based deployment with proper error handling

## ğŸ” Technical Details

### Data Preprocessing
- Missing value imputation using median values
- Categorical encoding with fallback handling
- Date feature extraction (year, month, day, days_since)
- Feature scaling and PCA transformation

### Model Architecture
- **Algorithm**: RandomForest (200 estimators)
- **Balancing**: SMOTE + class_weight='balanced'
- **Validation**: Stratified train-test split
- **Features**: PCA-reduced feature space (95% variance)

## ğŸ¢ Business Impact

This system enables banks to:
- Automate loan approval decisions
- Reduce manual underwriting time
- Standardize risk assessment criteria
- Improve portfolio quality through data-driven decisions
- Maintain regulatory compliance through transparent feature engineering

## ğŸ“‹ Future Enhancements

- Integration with OLLAMA/LLM models for explanatory AI
- Docker containerization for scalable deployment
- OpenWebUI integration for collaborative model management
- Real-time database connectivity
- Advanced ensemble methods and deep learning models

## ğŸ¤ Collaboration

This project was developed as part of a 3-person team during an NBK Egypt internship:
- Data extraction and preprocessing
- Feature engineering and model development
- DevOps integration with OLLAMA and Docker
- Streamlit UI development and deployment

---

**Note**: This repository contains one of multiple projects completed during the NBK Egypt internship. The data used is anonymized and processed according to banking privacy standards.
